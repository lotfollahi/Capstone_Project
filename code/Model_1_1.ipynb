{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import os\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '/home/ec2-user/Capstone_Project/code/left-pca16' # Full path should be given here \n",
    "train_mask_path = 'mask/train/'\n",
    "test_data_path = '/home/ec2-user/Capstone_Project/code/right-pca16' # Full path should be given here \n",
    "test_mask_path = 'mask/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data form training and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " balance:  True\n",
      "\n",
      " number of samples:  120000 \n",
      "\n",
      "loading class:  1  - samples:  20000\n",
      "loading class:  2  - samples:  20000\n",
      "loading class:  3  - samples:  20000\n",
      "loading class:  4  - samples:  20000\n",
      "loading class:  5  - samples:  20000\n",
      "loading class:  6  - samples:  19999\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train, num_bands = utils.load_data(data_path = train_data_path, \n",
    "                                             masks_path = train_mask_path, \n",
    "                                             crop_size = 33, \n",
    "                                             num_classes = 6, \n",
    "                                             samples = 50000, \n",
    "                                             balance = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " balance:  True\n",
      "\n",
      " number of samples:  120000 \n",
      "\n",
      "loading class:  1  - samples:  20000\n",
      "loading class:  2  - samples:  20000\n",
      "loading class:  3  - samples:  20000\n",
      "loading class:  4  - samples:  20000\n",
      "loading class:  5  - samples:  20000\n",
      "loading class:  6  - samples:  20000\n"
     ]
    }
   ],
   "source": [
    "X_test,Y_test, num_bands = utils.load_data(data_path = test_data_path, \n",
    "                                           masks_path = test_mask_path, \n",
    "                                           crop_size = 33, \n",
    "                                           num_classes = 6, \n",
    "                                           samples = 50000, \n",
    "                                           balance = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat generato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(119999, 33, 33, 16) (119999, 6) 16\n",
      "(120000, 33, 33, 16) (120000, 6) 16\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train), type(Y_train))\n",
    "print(X_train.shape, Y_train.shape, num_bands)\n",
    "print(X_test.shape,  Y_test.shape,  num_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([X_train[i] for i in range(X_train.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([X_test[i] for i in range(X_test.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array([Y_train[i,:] for i in range(Y_train.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.array([Y_test[i,:] for i in range(Y_test.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), strides=(1, 1), input_shape=(33, 33, 16), kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softplus'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), strides=(1, 1), kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softplus'))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), strides=(1, 1), kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softplus'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softplus'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(6, kernel_regularizer=l2(0.01)))\n",
    "model.add(Activation('softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119999 samples, validate on 120000 samples\n",
      "Epoch 1/20\n",
      "119999/119999 [==============================] - 43s 355us/step - loss: 0.9168 - acc: 0.9016 - val_loss: 1.1735 - val_acc: 0.7153\n",
      "Epoch 2/20\n",
      "119999/119999 [==============================] - 40s 336us/step - loss: 0.3637 - acc: 0.9310 - val_loss: 1.0323 - val_acc: 0.7483\n",
      "Epoch 3/20\n",
      "119999/119999 [==============================] - 42s 346us/step - loss: 0.3303 - acc: 0.9354 - val_loss: 0.9216 - val_acc: 0.7783\n",
      "Epoch 4/20\n",
      "119999/119999 [==============================] - 42s 348us/step - loss: 0.2975 - acc: 0.9418 - val_loss: 1.0106 - val_acc: 0.7234\n",
      "Epoch 5/20\n",
      "119999/119999 [==============================] - 42s 348us/step - loss: 0.2805 - acc: 0.9446 - val_loss: 1.3245 - val_acc: 0.6933\n",
      "Epoch 6/20\n",
      "119999/119999 [==============================] - 42s 348us/step - loss: 0.2691 - acc: 0.9469 - val_loss: 1.1043 - val_acc: 0.7199\n",
      "Epoch 7/20\n",
      "119999/119999 [==============================] - 43s 356us/step - loss: 0.2539 - acc: 0.9503 - val_loss: 1.0178 - val_acc: 0.7055\n",
      "Epoch 8/20\n",
      "119999/119999 [==============================] - 43s 357us/step - loss: 0.2457 - acc: 0.9513 - val_loss: 1.1550 - val_acc: 0.7189\n",
      "Epoch 9/20\n",
      "119999/119999 [==============================] - 43s 358us/step - loss: 0.2344 - acc: 0.9532 - val_loss: 1.3631 - val_acc: 0.6449\n",
      "Epoch 10/20\n",
      "119999/119999 [==============================] - 43s 356us/step - loss: 0.2239 - acc: 0.9554 - val_loss: 1.0132 - val_acc: 0.7486\n",
      "Epoch 11/20\n",
      "119999/119999 [==============================] - 43s 357us/step - loss: 0.2186 - acc: 0.9565 - val_loss: 0.7638 - val_acc: 0.8088\n",
      "Epoch 12/20\n",
      "119999/119999 [==============================] - 43s 357us/step - loss: 0.2097 - acc: 0.9585 - val_loss: 1.0932 - val_acc: 0.7842\n",
      "Epoch 13/20\n",
      "119999/119999 [==============================] - 43s 357us/step - loss: 0.2046 - acc: 0.9591 - val_loss: 0.9421 - val_acc: 0.7540\n",
      "Epoch 14/20\n",
      "119999/119999 [==============================] - 43s 356us/step - loss: 0.1983 - acc: 0.9603 - val_loss: 0.8967 - val_acc: 0.7783\n",
      "Epoch 15/20\n",
      "119999/119999 [==============================] - 43s 356us/step - loss: 0.1957 - acc: 0.9606 - val_loss: 0.9220 - val_acc: 0.8020\n",
      "Epoch 16/20\n",
      "119999/119999 [==============================] - 43s 355us/step - loss: 0.1960 - acc: 0.9604 - val_loss: 0.9496 - val_acc: 0.7783\n",
      "Epoch 17/20\n",
      "119999/119999 [==============================] - 43s 356us/step - loss: 0.1924 - acc: 0.9615 - val_loss: 0.8975 - val_acc: 0.7848\n",
      "Epoch 18/20\n",
      "119999/119999 [==============================] - 43s 356us/step - loss: 0.1891 - acc: 0.9628 - val_loss: 0.9812 - val_acc: 0.7542\n",
      "Epoch 19/20\n",
      "119999/119999 [==============================] - 43s 356us/step - loss: 0.1896 - acc: 0.9621 - val_loss: 0.9091 - val_acc: 0.7776\n",
      "Epoch 20/20\n",
      "119999/119999 [==============================] - 43s 355us/step - loss: 0.1927 - acc: 0.9616 - val_loss: 1.4309 - val_acc: 0.7691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0929da9438>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          epochs = 20,\n",
    "          verbose = 1,\n",
    "          batch_size= 128,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
