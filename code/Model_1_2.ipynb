{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import os\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import load_model\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '/home/ec2-user/Capstone_Project/code/left-pca16' # Full path should be given here \n",
    "train_mask_path = 'mask/train/'\n",
    "test_data_path = '/home/ec2-user/Capstone_Project/code/right-pca16' # Full path should be given here \n",
    "test_mask_path = 'mask/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data form training and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " balance:  True\n",
      "\n",
      " number of samples:  300000 \n",
      "\n",
      "loading class:  1  - samples:  50000\n",
      "loading class:  2  - samples:  50000\n",
      "loading class:  3  - samples:  50000\n",
      "loading class:  4  - samples:  50000\n",
      "loading class:  5  - samples:  50000\n",
      "loading class:  6  - samples:  49999\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train, num_bands = utils.load_data(data_path = train_data_path, \n",
    "                                             masks_path = train_mask_path, \n",
    "                                             crop_size = 33, \n",
    "                                             num_classes = 6, \n",
    "                                             samples = 50000, \n",
    "                                             balance = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " balance:  True\n",
      "\n",
      " number of samples:  60000 \n",
      "\n",
      "loading class:  1  - samples:  10000\n",
      "loading class:  2  - samples:  10000\n",
      "loading class:  3  - samples:  10000\n",
      "loading class:  4  - samples:  10000\n",
      "loading class:  5  - samples:  10000\n",
      "loading class:  6  - samples:  10000\n"
     ]
    }
   ],
   "source": [
    "X_test,Y_test, num_bands = utils.load_data(data_path = test_data_path, \n",
    "                                           masks_path = test_mask_path, \n",
    "                                           crop_size = 33, \n",
    "                                           num_classes = 6, \n",
    "                                           samples = 10000, \n",
    "                                           balance = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat generato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(299999, 33, 33, 16) (299999, 6) 16\n",
      "(60000, 33, 33, 16) (60000, 6) 16\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train), type(Y_train))\n",
    "print(X_train.shape, Y_train.shape, num_bands)\n",
    "print(X_test.shape,  Y_test.shape,  num_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([X_train[i] for i in range(X_train.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([X_test[i] for i in range(X_test.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array([Y_train[i,:] for i in range(Y_train.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.array([Y_test[i,:] for i in range(Y_test.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), strides=(1, 1), input_shape=(33, 33, 16), kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softplus'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), strides=(1, 1), kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softplus'))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), strides=(1, 1), kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softplus'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softplus'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(6, kernel_regularizer=l2(0.01)))\n",
    "model.add(Activation('softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(lr=0.1, rho=0.95, epsilon=1e-07, decay=0.0),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 299999 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "299999/299999 [==============================] - 81s 270us/step - loss: 1.9166 - acc: 0.9126 - val_loss: 1.5401 - val_acc: 0.7582\n",
      "Epoch 2/20\n",
      "299999/299999 [==============================] - 76s 252us/step - loss: 0.6142 - acc: 0.9577 - val_loss: 1.0519 - val_acc: 0.7821\n",
      "Epoch 3/20\n",
      "299999/299999 [==============================] - 75s 249us/step - loss: 0.3888 - acc: 0.9673 - val_loss: 1.2569 - val_acc: 0.7017\n",
      "Epoch 4/20\n",
      "299999/299999 [==============================] - 75s 248us/step - loss: 0.2913 - acc: 0.9723 - val_loss: 1.3145 - val_acc: 0.7055\n",
      "Epoch 5/20\n",
      "299999/299999 [==============================] - 74s 248us/step - loss: 0.2372 - acc: 0.9753 - val_loss: 0.7081 - val_acc: 0.8267\n",
      "Epoch 6/20\n",
      "299999/299999 [==============================] - 74s 248us/step - loss: 0.2038 - acc: 0.9771 - val_loss: 0.8798 - val_acc: 0.7805\n",
      "Epoch 7/20\n",
      "299999/299999 [==============================] - 75s 249us/step - loss: 0.1795 - acc: 0.9791 - val_loss: 0.7906 - val_acc: 0.8388\n",
      "Epoch 8/20\n",
      "299999/299999 [==============================] - 75s 249us/step - loss: 0.1629 - acc: 0.9803 - val_loss: 1.1041 - val_acc: 0.7481\n",
      "Epoch 9/20\n",
      "299999/299999 [==============================] - 75s 248us/step - loss: 0.1507 - acc: 0.9812 - val_loss: 0.8510 - val_acc: 0.8212\n",
      "Epoch 10/20\n",
      "299999/299999 [==============================] - 75s 249us/step - loss: 0.1406 - acc: 0.9818 - val_loss: 0.5577 - val_acc: 0.8750\n",
      "Epoch 11/20\n",
      "299999/299999 [==============================] - 75s 250us/step - loss: 0.1330 - acc: 0.9825 - val_loss: 0.6890 - val_acc: 0.8256\n",
      "Epoch 12/20\n",
      "299999/299999 [==============================] - 75s 251us/step - loss: 0.1266 - acc: 0.9833 - val_loss: 1.0398 - val_acc: 0.7514\n",
      "Epoch 13/20\n",
      "299999/299999 [==============================] - 74s 248us/step - loss: 0.1213 - acc: 0.9838 - val_loss: 0.8315 - val_acc: 0.8182\n",
      "Epoch 14/20\n",
      "299999/299999 [==============================] - 74s 247us/step - loss: 0.1165 - acc: 0.9844 - val_loss: 0.8658 - val_acc: 0.7900\n",
      "Epoch 15/20\n",
      "299999/299999 [==============================] - 74s 247us/step - loss: 0.1117 - acc: 0.9849 - val_loss: 0.8081 - val_acc: 0.7982\n",
      "Epoch 16/20\n",
      "299999/299999 [==============================] - 74s 247us/step - loss: 0.1086 - acc: 0.9854 - val_loss: 1.2132 - val_acc: 0.7208\n",
      "Epoch 17/20\n",
      "299999/299999 [==============================] - 74s 247us/step - loss: 0.1056 - acc: 0.9855 - val_loss: 0.6729 - val_acc: 0.8253\n",
      "Epoch 18/20\n",
      "299999/299999 [==============================] - 75s 250us/step - loss: 0.1033 - acc: 0.9855 - val_loss: 0.7423 - val_acc: 0.8004\n",
      "Epoch 19/20\n",
      "299999/299999 [==============================] - 74s 247us/step - loss: 0.0998 - acc: 0.9864 - val_loss: 0.7560 - val_acc: 0.7963\n",
      "Epoch 20/20\n",
      "299999/299999 [==============================] - 75s 249us/step - loss: 0.0975 - acc: 0.9867 - val_loss: 0.8842 - val_acc: 0.7785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4db81d90b8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          epochs = 20,\n",
    "          verbose = 1,\n",
    "          batch_size= 128,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_1_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_1_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this make aure all the layers are trainable\n",
    "# for layer in model.layers:\n",
    "#     print(layer.trainable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
