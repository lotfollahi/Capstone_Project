{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import os\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_data_path = '/home/ec2-user/code/left-pca16' # Full path should be given here \n",
    "# train_mask_path = 'mask/train/'\n",
    "# test_data_path = '/home/ec2-user/code/right-pca16' # Full path should be given here \n",
    "# test_mask_path = 'mask/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "folder = 'mask/train/'\n",
    "path = []\n",
    "for filename in os.listdir('mask/train/'):\n",
    "    files.append(filename)\n",
    "    path.append('{}{}'.format(folder,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axs = axs.ravel()\n",
    "for i in range(len(path)):\n",
    "    img = load_img(path=path[i],grayscale=True, target_size=(150,150), interpolation='nearest')\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].set_title(files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "folder = 'mask/test/'\n",
    "path = []\n",
    "for filename in os.listdir('mask/test/'):\n",
    "    files.append(filename)\n",
    "    path.append('{}{}'.format(folder,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axs = axs.ravel()\n",
    "for i in range(len(path)):\n",
    "    img = load_img(path=path[i],grayscale=True, target_size=(150,150), interpolation='nearest')\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].set_title(files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data form training and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_path = '/Users/mlotfollahi/Desktop/Galvanize/Capstone_Project/code/left-pca16' # Full path should be given here \n",
    "train_mask_path = 'mask/train/'\n",
    "\n",
    "test_data_path = '/Users/mlotfollahi/Desktop/Galvanize/Capstone_Project/code/right-pca16' # Full path should be given here \n",
    "test_mask_path = 'mask/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " balance:  True\n",
      "\n",
      " number of samples:  6000 \n",
      "\n",
      "loading class:  1  - samples:  1000\n",
      "loading class:  2  - samples:  1000\n",
      "loading class:  3  - samples:  1000\n",
      "loading class:  4  - samples:  1000\n",
      "loading class:  5  - samples:  1000\n",
      "loading class:  6  - samples:  1000\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train, num_bands = utils.load_data(data_path = train_data_path, \n",
    "                                             masks_path = train_mask_path, \n",
    "                                             crop_size = 33, \n",
    "                                             num_classes = 6, \n",
    "                                             samples = 1000, \n",
    "                                             balance = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_test,Y_test, num_bands = utils.load_data(data_path = test_data_path, \n",
    "#                                            masks_path = test_mask_path, \n",
    "#                                            crop_size = 33, \n",
    "#                                            num_classes = 6, \n",
    "#                                            samples = 100000, \n",
    "#                                            balance = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creat generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DataGenerator(data_path, masks_path, crop_size, num_classes, samples = 1000, balance = True):  \n",
    "    while True:\n",
    "        X, Y, num_bands = utils.load_data(data_path, \n",
    "                                          masks_path, \n",
    "                                          crop_size, \n",
    "                                          num_classes, \n",
    "                                          samples,\n",
    "                                          balance)\n",
    "        X_for_keras = np.array([X[i] for i in range(X.shape[0])])\n",
    "        Y_for_keras = np.array([Y[i,:] for i in range(Y.shape[0])])\n",
    "        yield X_for_keras, Y_for_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(data_path = train_data_path, \n",
    "                                   masks_path = train_mask_path, \n",
    "                                   crop_size = 33, \n",
    "                                   num_classes = 6, \n",
    "                                   samples = 10, \n",
    "                                   balance = True,\n",
    "                                   num_of_batches = 10)\n",
    "\n",
    "\n",
    "validation_generator = DataGenerator(data_path = test_data_path, \n",
    "                               masks_path = test_mask_path, \n",
    "                               crop_size = 33, \n",
    "                               num_classes = 6, \n",
    "                               samples = 10, \n",
    "                               balance = True,\n",
    "                               num_of_batches = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(type(X_train), type(Y_train))\n",
    "print(X_train.shape, Y_train.shape, num_bands)\n",
    "print(X_test.shape,  Y_test.shape,  num_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_list = np.array([X_train[i] for i in range(X_train.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_list = np.array([X_test[i] for i in range(X_test.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train_list = np.array([Y_train[i,:] for i in range(Y_train.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test_list = np.array([Y_test[i,:] for i in range(Y_test.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), input_shape=(33, 33, 16)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(6))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=8, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=(33, 33, 16),\n",
    "                 kernel_regularizer=l2(0.01)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                       strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5),\n",
    "                 strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer=l2(0.01)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                       strides=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,\n",
    "                activation='relu',\n",
    "                kernel_regularizer=l2(0.01)))\n",
    "model.add(Dense(6,\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`steps_per_epoch=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps_per_epoch` or use the `keras.utils.Sequence` class.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b02794f9854c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     validation_data=validation_generator)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             raise ValueError('`steps_per_epoch=None` is only valid for a'\n\u001b[0m\u001b[1;32m     55\u001b[0m                              \u001b[0;34m' generator based on the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                              \u001b[0;34m'`keras.utils.Sequence`'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `steps_per_epoch=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps_per_epoch` or use the `keras.utils.Sequence` class."
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs = 10,\n",
    "    validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.fit(X_train_list, Y_train_list,\n",
    "#           epochs = 5,\n",
    "#           verbose = 1,\n",
    "#           batch_size= 50,\n",
    "#           validation_data=(X_test_list, Y_test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # read data from S3\n",
    "# import boto3\n",
    "# client = boto3.client('s3') \n",
    "# #s3 = boto3.resource('s3')\n",
    "# client.list_objects(Bucket=s3_bucket, Prefix = \"{}/\".format(subdirectory), Delimiter='/')['Contents']\n",
    "# s3_bucket = 'capstonelotfollahi'\n",
    "# subdirectory = 'left-pca16'\n",
    "# s3.list_objects(Bucket=s3_bucket, Prefix = \"{}/\".format(subdirectory), Delimiter='/')[\"Contents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  # Build and return a list\n",
    "# def firstn(n):\n",
    "#     num, nums = 0, []\n",
    "#     while num < n:\n",
    "#         nums.append(num)\n",
    "#         num += 1     \n",
    "#     return nums\n",
    "# sum_of_first_n = sum(firstn(1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def createGenerator():\n",
    "#     mylist = range(3)\n",
    "#     for i in mylist:\n",
    "#         yield i*i, i*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gen = createGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
